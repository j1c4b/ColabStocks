{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmN+nHb40KPms2uTqVvFjq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j1c4b/ColabStocks/blob/main/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBPy-eZJg_pA",
        "outputId": "a12612f7-0b37-4109-ebf3-31864d3f520f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# prompt: import bs4 frombeautiful soap and requests\n",
        "\n",
        "!pip install beautifulsoup4 requests\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create web scalping python code to get reporting  date, company, current price, rating from https://www.marketbeat.com/ratings/ using  bs4 from beautiful soap and requests\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_marketbeat():\n",
        "    url = \"https://www.marketbeat.com/ratings/\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find the table containing the data\n",
        "    table = soup.find(\"table\", class_=\"table table-striped table-hover\")  # Replace with actual class if different\n",
        "\n",
        "    if not table:\n",
        "        print(\"Table not found on page.\")\n",
        "        return []\n",
        "\n",
        "    data = []\n",
        "    rows = table.find_all(\"tr\")\n",
        "    for row in rows[1:]:  # Skip header row\n",
        "      cols = row.find_all(\"td\")\n",
        "      if len(cols) >= 4:  # Check if there are at least 4 columns\n",
        "          reporting_date = cols[0].text.strip()\n",
        "          company = cols[1].text.strip()\n",
        "          try:\n",
        "              current_price = float(cols[2].text.strip().replace('$','')) # Convert price to float\n",
        "          except ValueError:\n",
        "              current_price = None # Handle cases where price might not be a number\n",
        "          rating = cols[3].text.strip()\n",
        "\n",
        "          data.append({\n",
        "              \"reporting_date\": reporting_date,\n",
        "              \"company\": company,\n",
        "              \"current_price\": current_price,\n",
        "              \"rating\": rating\n",
        "          })\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "scraped_data = scrape_marketbeat()\n",
        "for item in scraped_data:\n",
        "  item\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR9X-f1GhZNG",
        "outputId": "7aa70253-c250-497c-fa11-65130ed4db4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table not found on page.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of MarketBeat's Analyst Ratings page\n",
        "URL = \"https://www.marketbeat.com/ratings/\"\n",
        "\n",
        "# Set headers to mimic a real browser\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# File path\n",
        "file_path = \"marketbeat_analyst_ratings.csv\"\n",
        "\n",
        "# Check if file exists and delete if it does\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"Existing file '{file_path}' deleted.\")\n",
        "\n",
        "print(f\"File location: {os.path.abspath(file_path)}\")\n",
        "\n",
        "# Request the page\n",
        "response = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Find the table containing analyst ratings\n",
        "    table = soup.find(\"table\", class_=\"scroll-table sort-table\")\n",
        "\n",
        "    if table:\n",
        "        data = []\n",
        "        rows = table.find_all(\"tr\")[1:]  # Skip the header row\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "\n",
        "            # Check if the row has enough columns before accessing them\n",
        "            if len(cols) >= 4:  # Make sure we have all the columns we need\n",
        "                # Extract necessary details\n",
        "            #    reporting_date = cols[0].text.strip()\n",
        "            # Extract 'Symbol|Company' and split it into two parts\n",
        "                symbol_company = cols[0].get(\"data-clean\", \"\").strip()  # Get the attribute value\n",
        "                symbol, company = symbol_company.split(\"|\") if \"|\" in symbol_company else (symbol_company, \"\")\n",
        "\n",
        "              #  symbol = cols[0].text.strip()\n",
        "                action = cols[1].text.strip()\n",
        "                current_price_price_change =cols[4].get(\"data-clean\", \"\").strip()  # Get the attribute value\n",
        "                current_price, price_change = current_price_price_change.split(\"|\") if \"|\" in current_price_price_change else (current_price_price_change, \"\")\n",
        "\n",
        "              #  cols[4].text.strip().replace('$','')\n",
        "                rating = cols[6].text.strip()\n",
        "\n",
        "                # Store the extracted data\n",
        "               # data.append([reporting_date, company, current_price, rating])\n",
        "                data.append([symbol, company, action, current_price, price_change, rating])\n",
        "\n",
        "        # Convert to DataFrame for easy manipulation\n",
        "       # df = pd.DataFrame(data, columns=[\"Reporting Date\", \"Company\", \"Current Price\", \"Rating\"])\\\n",
        "        df = pd.DataFrame(data, columns=[\"Symbol\", \"Company\", \"Action\", \"Current Price\", \"Price Change\", \"Rating\"])\n",
        "\n",
        "        # Print the extracted data\n",
        "        print(df)\n",
        "\n",
        "        # Save to CSV (optional)\n",
        "        df.to_csv(\"marketbeat_analyst_ratings.csv\", index=False)\n",
        "        print(\"\\n✅ Data saved to 'marketbeat_analyst_ratings.csv'\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ Failed to find the ratings table.\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Request failed with status code {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dP-K2wnmi99",
        "outputId": "2bacccfd-024e-4faf-d96e-acf0b1b11899"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing file 'marketbeat_analyst_ratings.csv' deleted.\n",
            "File location: /content/marketbeat_analyst_ratings.csv\n",
            "    Symbol                  Company             Action Current Price  \\\n",
            "0     AAOI  Applied Optoelectronics      Reiterated by        $21.86   \n",
            "1     AAPL                    Apple      Reiterated by       $212.21   \n",
            "2     ABNB                   Airbnb   Target Raised by       $122.19   \n",
            "3     ACIU                AC Immune      Reiterated by         $2.30   \n",
            "4      ACN                Accenture  Target Lowered by       $316.63   \n",
            "..     ...                      ...                ...           ...   \n",
            "201    WAY                  Waystar       Initiated by        $36.10   \n",
            "202   WEST          Westrock Coffee      Reiterated by         $6.78   \n",
            "203   XPOF       Xponential Fitness  Target Lowered by         $7.54   \n",
            "204   XPOF       Xponential Fitness  Target Lowered by         $7.54   \n",
            "205   XPOF       Xponential Fitness      Downgraded by         $7.54   \n",
            "\n",
            "    Price Change                   Rating  \n",
            "0          37.7%                Buy ➝ Buy  \n",
            "1           1.2%  Outperform ➝ Outperform  \n",
            "2           2.4%                Buy ➝ Buy  \n",
            "3           0.0%                Buy ➝ Buy  \n",
            "4          -0.1%  Overweight ➝ Overweight  \n",
            "..           ...                      ...  \n",
            "201         2.4%                      Buy  \n",
            "202        23.0%                Buy ➝ Buy  \n",
            "203       -37.8%        Neutral ➝ Neutral  \n",
            "204       -37.8%        Neutral ➝ Neutral  \n",
            "205       -37.8%               Buy ➝ Hold  \n",
            "\n",
            "[206 rows x 6 columns]\n",
            "\n",
            "✅ Data saved to 'marketbeat_analyst_ratings.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9hxpOChsovhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add code to above to send result file to gcp buskewt\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# --- Previous code ---\n",
        "\n",
        "# --- New code to upload to GCS ---\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'colab-sample-bucket-' + str(uuid.uuid1())\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}\n",
        "\n",
        "# Copy the file to our new bucket.\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!gsutil cp marketbeat_analyst_ratings.csv gs://{bucket_name}/\n",
        "\n",
        "# Finally, dump the contents of our newly copied file to make sure everything worked.\n",
        "!gsutil cat gs://{bucket_name}/marketbeat_analyst_ratings.csv\n"
      ],
      "metadata": {
        "id": "XUHYNLaJxL9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k9_0gQZzi-Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of MarketBeat's Analyst Ratings page\n",
        "URL = \"https://www.marketbeat.com/ratings/\"\n",
        "\n",
        "# Set headers to mimic a real browser\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# File path\n",
        "file_path = \"marketbeat_analyst_ratings.csv\"\n",
        "\n",
        "# Check if file exists and delete if it does\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"Existing file '{file_path}' deleted.\")\n",
        "\n",
        "print(f\"File location: {os.path.abspath(file_path)}\")\n",
        "\n",
        "# Request the page\n",
        "response = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Find the table containing analyst ratings\n",
        "    table = soup.find(\"table\", class_=\"scroll-table sort-table\")\n",
        "\n",
        "    if table:\n",
        "        data = []\n",
        "        rows = table.find_all(\"tr\")[1:]  # Skip the header row\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "\n",
        "            # Check if the row has enough columns before accessing them\n",
        "            if len(cols) >= 4:  # Make sure we have all the columns we need\n",
        "                # Extract necessary details\n",
        "            #    reporting_date = cols[0].text.strip()\n",
        "            # Extract 'Symbol|Company' and split it into two parts\n",
        "                symbol_company = cols[0].get(\"data-clean\", \"\").strip()  # Get the attribute value\n",
        "                symbol, company = symbol_company.split(\"|\") if \"|\" in symbol_company else (symbol_company, \"\")\n",
        "\n",
        "              #  symbol = cols[0].text.strip()\n",
        "                action = cols[1].text.strip()\n",
        "                current_price_price_change =cols[4].get(\"data-clean\", \"\").strip()  # Get the attribute value\n",
        "                current_price, price_change = current_price_price_change.split(\"|\") if \"|\" in current_price_price_change else (current_price_price_change, \"\")\n",
        "\n",
        "              #  cols[4].text.strip().replace('$','')\n",
        "                rating = cols[6].text.strip()\n",
        "\n",
        "                # Store the extracted data\n",
        "               # data.append([reporting_date, company, current_price, rating])\n",
        "                data.append([symbol, company, action, current_price, price_change, rating])\n",
        "\n",
        "        # Convert to DataFrame for easy manipulation\n",
        "       # df = pd.DataFrame(data, columns=[\"Reporting Date\", \"Company\", \"Current Price\", \"Rating\"])\\\n",
        "        df = pd.DataFrame(data, columns=[\"Symbol\", \"Company\", \"Action\", \"Current Price\", \"Price Change\", \"Rating\"])\n",
        "\n",
        "        # Print the extracted data\n",
        "        print(df)\n",
        "\n",
        "        # Save to CSV (optional)\n",
        "        df.to_csv(\"marketbeat_analyst_ratings.csv\", index=False)\n",
        "        print(\"\\n✅ Data saved to 'marketbeat_analyst_ratings.csv'\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ Failed to find the ratings table.\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Request failed with status code {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6JBHaaxxI2_",
        "outputId": "624fd027-3023-41d8-fb78-13f5899c3f05"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing file 'marketbeat_analyst_ratings.csv' deleted.\n",
            "File location: /content/marketbeat_analyst_ratings.csv\n",
            "    Symbol                  Company             Action Current Price  \\\n",
            "0     AAOI  Applied Optoelectronics      Reiterated by        $22.15   \n",
            "1     AAPL                    Apple      Reiterated by       $212.20   \n",
            "2     ABNB                   Airbnb   Target Raised by       $122.00   \n",
            "3     ACIU                AC Immune      Reiterated by         $2.29   \n",
            "4      ACN                Accenture  Target Lowered by       $316.19   \n",
            "..     ...                      ...                ...           ...   \n",
            "201    WAY                  Waystar       Initiated by        $36.13   \n",
            "202   WEST          Westrock Coffee      Reiterated by         $6.78   \n",
            "203   XPOF       Xponential Fitness  Target Lowered by         $7.53   \n",
            "204   XPOF       Xponential Fitness  Target Lowered by         $7.53   \n",
            "205   XPOF       Xponential Fitness      Downgraded by         $7.53   \n",
            "\n",
            "    Price Change                   Rating  \n",
            "0          39.6%                Buy ➝ Buy  \n",
            "1           1.2%  Outperform ➝ Outperform  \n",
            "2           2.2%                Buy ➝ Buy  \n",
            "3          -0.4%                Buy ➝ Buy  \n",
            "4          -0.3%  Overweight ➝ Overweight  \n",
            "..           ...                      ...  \n",
            "201         2.4%                      Buy  \n",
            "202        23.0%                Buy ➝ Buy  \n",
            "203       -37.9%        Neutral ➝ Neutral  \n",
            "204       -37.9%        Neutral ➝ Neutral  \n",
            "205       -37.9%               Buy ➝ Hold  \n",
            "\n",
            "[206 rows x 6 columns]\n",
            "\n",
            "✅ Data saved to 'marketbeat_analyst_ratings.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: modify above code to be run from ubuntu directory /home/user_name/projects/python_apps/stock_raiting\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import uuid\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Install necessary libraries if not already installed\n",
        "!pip install beautifulsoup4 requests gspread oauth2client\n",
        "\n",
        "# Authenticate with Google Drive/Sheets\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Specify the file path\n",
        "file_path = \"/home/user_name/projects/python_apps/stock_raiting/marketbeat_analyst_ratings.csv\"\n",
        "\n",
        "\n",
        "def scrape_marketbeat():\n",
        "    # ... (rest of your scraping function code)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "scraped_data = scrape_marketbeat()  # Assuming you have this function defined\n",
        "# ... (rest of your code to process scraped_data)\n",
        "\n",
        "# ... (rest of the code to scrape and save to csv)\n",
        "\n",
        "\n",
        "# --- New code to upload to Google Sheets ---\n",
        "try:\n",
        "    # Open the spreadsheet (replace with your actual spreadsheet name or ID)\n",
        "    spreadsheet_name = \"Your Spreadsheet Name\"  # Replace with the name of your spreadsheet\n",
        "    sh = gc.open(spreadsheet_name)\n",
        "\n",
        "    # Select the worksheet (replace with your actual worksheet name)\n",
        "    worksheet_name = \"Sheet1\" # Replace with the name of your worksheet\n",
        "    worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "    # Read the CSV data into a pandas DataFrame\n",
        "    df = pd.read_csv(file_path)  # Now using the specified file path\n",
        "\n",
        "    # Clear existing data in the worksheet (optional)\n",
        "    worksheet.clear()\n",
        "\n",
        "    # Update the worksheet with the DataFrame data\n",
        "    worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "\n",
        "    print(f\"✅ Data successfully uploaded to Google Sheet: {spreadsheet_name}, Worksheet: {worksheet_name}\")\n",
        "\n",
        "except gspread.exceptions.SpreadsheetNotFound:\n",
        "    print(f\"❌ Spreadsheet '{spreadsheet_name}' not found.\")\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(f\"❌ Worksheet '{worksheet_name}' not found in spreadsheet '{spreadsheet_name}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "B6QUYwybOAj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBD5b8aEOBPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WHDC4v4COBhy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3J3qM0h-OB3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JzuA4mYcOCrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add code to send result file in email\n",
        "\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "\n",
        "def send_email(sender_email, sender_password, receiver_email, subject, body, filename):\n",
        "    # Create a multipart message\n",
        "    message = MIMEMultipart()\n",
        "    message[\"From\"] = sender_email\n",
        "    message[\"To\"] = receiver_email\n",
        "    message[\"Subject\"] = subject\n",
        "\n",
        "    # Add body to email\n",
        "    message.attach(MIMEText(body, \"plain\"))\n",
        "\n",
        "    # Open the file in binary mode\n",
        "    with open(filename, \"rb\") as attachment:\n",
        "        # Add file as application/octet-stream\n",
        "        # Email client can usually download this automatically as attachment\n",
        "        part = MIMEBase(\"application\", \"octet-stream\")\n",
        "        part.set_payload(attachment.read())\n",
        "\n",
        "    # Encode file in ASCII characters to send by email\n",
        "    encoders.encode_base64(part)\n",
        "\n",
        "    # Add header as key/value pair to attachment part\n",
        "    part.add_header(\n",
        "        \"Content-Disposition\",\n",
        "        f\"attachment; filename= {filename}\",\n",
        "    )\n",
        "\n",
        "    # Add attachment to message and convert message to string\n",
        "    message.attach(part)\n",
        "    text = message.as_string()\n",
        "\n",
        "    # Log in to server using secure context and send email\n",
        "    context = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
        "    context.login(sender_email, sender_password)\n",
        "    context.sendmail(sender_email, receiver_email, text)\n",
        "    context.quit()\n",
        "\n",
        "# Example usage\n",
        "sender_email = \"your_email@gmail.com\"  # Replace with your email\n",
        "sender_password = \"your_password\"  # Replace with your email password\n",
        "receiver_email = \"recipient_email@example.com\"  # Replace with recipient's email\n",
        "subject = \"Marketbeat Analyst Ratings\"\n",
        "body = \"Please find the attached Marketbeat Analyst Ratings file.\"\n",
        "filename = \"marketbeat_analyst_ratings.csv\"\n",
        "\n",
        "send_email(sender_email, sender_password, receiver_email, subject, body, filename)\n"
      ],
      "metadata": {
        "id": "i7bPs6Fqx1v_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}